{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import statsmodels.api as sm;\n",
    "import statsmodels.stats.api as sms;\n",
    "import statsmodels.discrete.discrete_model as smdiscrete\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('use_inf_as_na', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv(\"stockmetadata.csv\")\n",
    "fdata_df = pd.read_csv(\"corpfund.csv\")\n",
    "fdata_df = fdata_df[fdata_df['dimension']=='ARQ']\n",
    "fdata_df['datekey'] = pd.to_datetime(fdata_df['datekey'])\n",
    "df_left = pd.merge(fdata_df, meta_df, on='ticker', how='left')\n",
    "df_left = df_left.set_index('datekey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industrydummies = pd.get_dummies(df_left['sicsector'])\n",
    "industrydummies.sum()\t\t    # purely for exploring the data, has no other purpose\n",
    "industrydummies.describe()      # purely for exploring the data, has no other purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_dummies = pd.concat([df_left,industrydummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_dummies.drop(['Wholesale Trade'], inplace=True, axis=1)\t            # drop 1 dummy variable\n",
    "data_w_dummies['epratio'] = data_w_dummies['eps']/data_w_dummies['price']\t# generate dependent variable\n",
    "data_w_dummies['operatingmargin'] = data_w_dummies['opinc'] / data_w_dummies['revenue']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sm.OLS(data_w_dummies['epratio'], sm.add_constant(data_w_dummies[['operatingmargin']]), missing='drop').fit()\n",
    "result.summary()\n",
    "result = sm.OLS(\n",
    "    data_w_dummies['epratio'],\n",
    "    sm.add_constant(data_w_dummies[['operatingmargin', 'Agriculture Forestry And Fishing', 'Construction',\\\n",
    "                                    'Finance Insurance And Real Estate', 'Manufacturing', 'Mining', 'Retail Trade', 'Services',\\\n",
    "                                    'Transportation Communications Electric Gas And Sanitary Service']]), missing='drop').fit()\n",
    "result.summary()\n",
    "data_w_dummies['lnoperatingmargin'] = np.log(data_w_dummies['operatingmargin'])\n",
    "result = sm.OLS(data_w_dummies['epratio'], sm.add_constant(data_w_dummies[['lnoperatingmargin']]), missing='drop').fit()\n",
    "result.summary()\n",
    "data_w_dummies['lnepratio'] = np.log(data_w_dummies['epratio'])\n",
    "result = sm.OLS(data_w_dummies['lnepratio'], sm.add_constant(data_w_dummies[['lnoperatingmargin']]), missing='drop').fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$i$th dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sm.OLS(\n",
    "    data_w_dummies['lnepratio'],\n",
    "    sm.add_constant(data_w_dummies[['lnoperatingmargin', 'Agriculture Forestry And Fishing', 'Construction',\\\n",
    "                                    'Finance Insurance And Real Estate', 'Manufacturing', 'Mining', 'Retail Trade', 'Services',\\\n",
    "                                    'Transportation Communications Electric Gas And Sanitary Service']]), missing='drop').fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering standard variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because of a bug in python where fillna is not working perfectly\n",
    "data_w_dummies.dropna(subset = ['lnepratio', 'lnoperatingmargin'], inplace=True)\n",
    "\n",
    "# note that we can cannot cluster by str variables in python, hence using siccode instead of sicsector\n",
    "result = sm.OLS(\n",
    "    data_w_dummies['lnepratio'],\n",
    "    sm.add_constant(data_w_dummies[['lnoperatingmargin', 'Agriculture Forestry And Fishing', 'Construction',\\\n",
    "                                    'Finance Insurance And Real Estate', 'Manufacturing', 'Mining', 'Retail Trade', 'Services',\\\n",
    "                                    'Transportation Communications Electric Gas And Sanitary Service']]),\n",
    "    missing='drop').fit(cov_type='cluster', cov_kwds={'groups': data_w_dummies['siccode']})\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate categorical variable for probit/logit analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_dummies['paydividend'] = data_w_dummies['dps']>0\n",
    "data_w_dummies['paydividend']\t        # purely for describing data\n",
    "data_w_dummies['paydividend'].mean()\t# purely for describing data\n",
    "data_w_dummies['paydividend'] = data_w_dummies['paydividend'].astype(int)\t# formatting the data for estimation models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try using OLS anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sm.OLS(\n",
    "    data_w_dummies['paydividend'],\n",
    "    sm.add_constant(data_w_dummies[['lnoperatingmargin', 'Agriculture Forestry And Fishing', 'Construction',\\\n",
    "                                    'Finance Insurance And Real Estate', 'Manufacturing', 'Mining', 'Retail Trade', 'Services',\\\n",
    "                                    'Transportation Communications Electric Gas And Sanitary Service']]),\n",
    "    missing='drop').fit(cov_type='cluster', cov_kwds={'groups': data_w_dummies['siccode']})\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use logit instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = smdiscrete.Logit(\n",
    "    data_w_dummies['paydividend'],\n",
    "    sm.add_constant(data_w_dummies[['lnoperatingmargin', 'Agriculture Forestry And Fishing', 'Construction',\\\n",
    "                                    'Finance Insurance And Real Estate', 'Manufacturing', 'Mining', 'Retail Trade', 'Services',\\\n",
    "                                    'Transportation Communications Electric Gas And Sanitary Service']]),\n",
    "    missing='drop').fit(cov_type='cluster', cov_kwds={'groups': data_w_dummies['siccode']})\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "data = data_w_dummies  # renaming the variable for easier typing\n",
    "numerator = ['cashneq', 'debt', 'ebit', 'ebt', 'eps', 'equity', 'fcf', 'gp', 'inventory', 'liabilities', 'payables', 'receivables',\\\n",
    "             'tangibles', 'workingcapital']\n",
    "denominator = ['assets', 'revenue']\n",
    "featureslist = []\n",
    "for n in numerator:\n",
    "    for d in denominator:\n",
    "        tag = n+'_'+d\n",
    "        data[tag] = np.log(data[n]/data[d])\n",
    "        featureslist.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset=featureslist, inplace=True)\n",
    "features = data.loc[:, featureslist].values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "features = StandardScaler().fit_transform(features)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 4)\n",
    "principal_components = pca.fit_transform(features)\n",
    "principal_components\n",
    "pca.explained_variance_ratio_\n",
    "pc_df = pd.DataFrame(principal_components)\n",
    "pc_df.corr()\n",
    "pc_df.columns = ['PC1', 'PC2', 'PC3', 'PC4']\n",
    "pc_df.index = data.index\n",
    "data_merge = pd.concat([data, pc_df], axis=1)\n",
    "result = sm.OLS(data_merge['lnepratio'], sm.add_constant(data_merge[featureslist]),\n",
    "                missing='drop').fit(cov_type='cluster', cov_kwds={'groups': data_w_dummies['siccode']})\n",
    "print(result.summary())\n",
    "result = sm.OLS(data_merge['lnepratio'], sm.add_constant(data_merge[['PC1', 'PC2', 'PC3', 'PC4']]),\n",
    "                missing='drop').fit(cov_type='cluster', cov_kwds={'groups': data_w_dummies['siccode']})\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's figure out what 'PC1' means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureslist.append('PC1')\n",
    "data_merge[featureslist].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTERACTION VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = industrydummies.columns.values\n",
    "dummies = dummies[1:len(dummies)-1]\n",
    "dlist = []\n",
    "for ind in dummies:\n",
    "    tag = 'lnoperatingmargin'+'_'+ind\n",
    "    data[tag] = data['lnoperatingmargin']*(data[ind])\n",
    "    dlist.append(tag)\n",
    "    dlist.append(ind)\n",
    "dlist.append('lnoperatingmargin')\n",
    "result = sm.OLS(data['lnepratio'], sm.add_constant(data[dlist]),\n",
    "                missing='drop').fit(cov_type='cluster', cov_kwds={'groups': data_w_dummies['siccode']})\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQUARED VARIABLES<br>\n",
    "We hypothesize that a stock's valuation has a concave relationship to its asset tangiblility - why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tangibles_assets_normal'] = data['tangibles']/data['assets']\n",
    "data['tangibles_assets_sq'] = data['tangibles_assets_normal']*data['tangibles_assets_normal']\n",
    "result = sm.OLS(data['epratio'], sm.add_constant(data[['tangibles_assets_normal', 'tangibles_assets_sq']]),\n",
    "                missing='drop').fit(cov_type='cluster', cov_kwds={'groups': data_w_dummies['siccode']})\n",
    "print(result.summary())\n",
    "result = sm.OLS(data['epratio'], sm.add_constant(data[['tangibles_assets_normal']]),\n",
    "                missing='drop').fit(cov_type='cluster', cov_kwds={'groups': data_w_dummies['siccode']})\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAG INDEPENDENT VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merge.index=[data_merge['ticker'], data_merge.index]\n",
    "datalag1 = data_merge.groupby(level=0).shift(1)\n",
    "dataset = pd.concat([data_merge['lnepratio'], datalag1[['PC1', 'PC2', 'PC3', 'PC4']]], axis=1)\n",
    "dataset.dropna(inplace=True)\n",
    "result = sm.OLS(dataset['lnepratio'], sm.add_constant(dataset[['PC1', 'PC2', 'PC3', 'PC4']]), missing='drop').fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "formula = 'lnepratio ~ tangibles_assets_normal + tangibles_assets_sq + cashneq_assets + gp_assets + gp_revenue + fcf_assets'\n",
    "result = ols(formula, data).fit()\n",
    "hypothesis1 = '(tangibles_assets_normal = cashneq_assets), tangibles_assets_sq = -0.5'\n",
    "f_test = result.f_test(hypothesis1)\n",
    "print(f_test)\n",
    "hypothesis2 = '(gp_assets = gp_revenue)'\n",
    "f_Test2 = result.f_test(hypothesis2)\n",
    "print(f_Test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deliberately get an insignificant F-test result so we can see what that looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'epratio ~ tangibles_assets_normal + tangibles_assets_sq + cashneq_assets + gp_assets + gp_revenue + fcf_assets'\n",
    "result = ols(formula, data).fit()\n",
    "f_Test2 = result.f_test(hypothesis2)\n",
    "print(f_Test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durbin Watson and other diagnostics<br>\n",
    "We are just repeating these estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sm.OLS(\n",
    "    data_w_dummies['epratio'],\n",
    "    sm.add_constant(data_w_dummies[['operatingmargin', 'Agriculture Forestry And Fishing', 'Construction',\\\n",
    "                                    'Finance Insurance And Real Estate', 'Manufacturing', 'Mining', 'Retail Trade', 'Services',\\\n",
    "                                    'Transportation Communications Electric Gas And Sanitary Service']]), missing='drop').fit()\n",
    "result.summary()\n",
    "result = sm.OLS(\n",
    "    data_w_dummies['lnepratio'],\n",
    "    sm.add_constant(data_w_dummies[['lnoperatingmargin', 'Agriculture Forestry And Fishing', 'Construction',\\\n",
    "                                    'Finance Insurance And Real Estate', 'Manufacturing', 'Mining', 'Retail Trade', 'Services',\\\n",
    "                                    'Transportation Communications Electric Gas And Sanitary Service']]), missing='drop').fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESUCH-GODFREY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sm.OLS(\n",
    "    data_w_dummies['lnepratio'],\n",
    "    sm.add_constant(data_w_dummies[['lnoperatingmargin', 'Agriculture Forestry And Fishing', 'Construction',\\\n",
    "                                    'Finance Insurance And Real Estate', 'Manufacturing', 'Mining', 'Retail Trade', 'Services',\\\n",
    "                                    'Transportation Communications Electric Gas And Sanitary Service']]), missing='drop').fit()\n",
    "result.summary()\n",
    "from statsmodels.stats.diagnostic import acorr_breusch_godfrey as bg\n",
    "bg(result)\n",
    "bg(result, nlags=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLDFIELD-QUANDT test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.compat import lzip\n",
    "result = sm.OLS(data_w_dummies['lnepratio'], sm.add_constant(data_w_dummies[['lnoperatingmargin', 'Agriculture Forestry And Fishing', 'Construction','Finance Insurance And Real Estate', 'Manufacturing', 'Mining','Retail Trade', 'Services','Transportation Communications Electric Gas And Sanitary Service']]), missing='drop').fit()\n",
    "result.summary()\n",
    "GQ = sms.het_goldfeldquandt(result.resid, result.model.exog)\n",
    "lzip(['Fstat', 'pval'], GQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HITE test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import het_white\n",
    "result = sm.OLS(data_w_dummies['lnepratio'], sm.add_constant(data_w_dummies[['lnoperatingmargin', 'Agriculture Forestry And Fishing', 'Construction','Finance Insurance And Real Estate', 'Manufacturing', 'Mining','Retail Trade', 'Services','Transportation Communications Electric Gas And Sanitary Service']]), missing='drop').fit()\n",
    "result.summary()\n",
    "wtest = het_white(result.resid, result.model.exog)\n",
    "labels = ['Lagrange Multiplier statistic:', 'LM test\\'s p-value:', 'F-statistic:', 'F-test\\'s p-value:']\n",
    "lzip(labels, wtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ffect of additional logarithm filter on heterogeneity White's test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_dummies['lnlnepratio'] = np.log(data_w_dummies['lnepratio'] + 1)\n",
    "data_w_dummies['lnlnoperatingmargin'] = np.log(data_w_dummies['lnoperatingmargin'] + 1)\n",
    "result = sm.OLS(data_w_dummies['lnlnepratio'], sm.add_constant(data_w_dummies[['lnlnoperatingmargin', 'Agriculture Forestry And Fishing', 'Construction','Finance Insurance And Real Estate', 'Manufacturing', 'Mining','Retail Trade', 'Services','Transportation Communications Electric Gas And Sanitary Service']]), missing='drop').fit()\n",
    "result.summary()\n",
    "wtest = het_white(result.resid, result.model.exog)\n",
    "labels = ['Lagrange Multiplier statistic:', 'LM test\\'s p-value:', 'F-statistic:', 'F-test\\'s p-value:']\n",
    "lzip(labels, wtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "amsey's RESET test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import linear_reset as lr\n",
    "result = sm.OLS(data_w_dummies['lnepratio'], sm.add_constant(data_w_dummies[['lnoperatingmargin', 'Agriculture Forestry And Fishing', 'Construction','Finance Insurance And Real Estate', 'Manufacturing', 'Mining','Retail Trade', 'Services','Transportation Communications Electric Gas And Sanitary Service']]), missing='drop').fit()\n",
    "lr(result, power = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ry to improve result on RESET test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_dummies['lnom_sq'] = data_w_dummies['lnoperatingmargin']**2\n",
    "data_w_dummies['lnom_cu'] = data_w_dummies['lnoperatingmargin']**3\n",
    "result = sm.OLS(data_w_dummies['lnepratio'], sm.add_constant(data_w_dummies[['lnoperatingmargin', 'lnom_sq', 'lnom_cu', 'Agriculture Forestry And Fishing', 'Construction','Finance Insurance And Real Estate', 'Manufacturing', 'Mining','Retail Trade', 'Services','Transportation Communications Electric Gas And Sanitary Service']]), missing='drop').fit()\n",
    "lr(result, power = 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
